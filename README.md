**Soil Analyzer â€” AI-Powered Soil Report Interpreter**

An intelligent web app that analyzes soil test reports (PDFs) using LangChain, Google Gemini, and Chroma Vector Database.
It extracts, indexes, and interprets soil data â€” providing quality assessment, crop recommendations, and improvement suggestions.

**Features**

ğŸ“„ PDF Upload & Text Extraction â€“ Upload your soil test reports directly.
ğŸ§  LLM-based Soil Analysis â€“ Uses Google Gemini (via LangChain) to interpret test data.
ğŸ” Vector Database Integration â€“ Stores all uploaded reports in Chroma DB for semantic retrieval.
ğŸ’¬ Contextual RAG (Retrieval-Augmented Generation) â€“ Enriches current analysis using similar historical data.
ğŸ§¾ Structured Output â€“ Results are parsed into a Pydantic schema for consistent display.
âš™ï¸ Streamlit Interface â€“ Interactive, easy-to-use web UI.

**Tech Stack**
| Component                | Technology                                                          |
| ------------------------ | ------------------------------------------------------------------- |
| **Language Model (LLM)** | [Google Gemini](https://ai.google.dev) via `langchain-google-genai` |
| **Framework**            | [LangChain](https://python.langchain.com)                           |
| **Vector Database**      | [Chroma](https://www.trychroma.com)                                 |
| **Embeddings**           | `text-embedding-004`                                                |
| **Frontend**             | [Streamlit](https://streamlit.io)                                   |
| **Parser**               | PydanticOutputParser                                                |
| **File Processing**      | PyMuPDF (for PDF text extraction)                                   |

**Project Structure**
SoilAnalyzer/
â”‚
â”œâ”€â”€ main.py               # Streamlit entry point (UI + orchestration)
â”œâ”€â”€ model.py              # LLM configuration (Gemini setup)
â”œâ”€â”€ prompt.py             # Prompt template + Pydantic schema
â”œâ”€â”€ db.py                 # Vector DB functions (Chroma setup, chunking, retrieval)
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .gitignore            # Ignored files (venv, chroma_db, etc.)
â””â”€â”€ chroma_db/            # Local Chroma vector database (auto-created)

**Setup Instructions**
1. Clone the repository
git clone https://github.com/PS-Saiyad-Uveshali/SoilAnalyzer.git
cd SoilAnalyzer

2. Install dependencies
pip install -r requirements.txt

3. Add your API key
  Create a Streamlit secrets file:
    mkdir -p .streamlit
  Create .streamlit/secrets.toml:
    GOOGLE_API_KEY = "your-google-genai-api-key-here"

**How It Works**
ğŸ§¾ Step 1 â€” Upload PDF

User uploads a soil test report (PDF).
PyMuPDF extracts the text page-by-page.

ğŸ” Step 2 â€” Index into Vector DB

Text is chunked (â‰ˆ1200 chars overlap 200).
Embeddings are created using Googleâ€™s text-embedding-004.
Stored locally in ChromaDB (chroma_db/) with metadata (source, page).

ğŸ’¡ Step 3 â€” Retrieval + LLM Analysis

When analyzing, the app retrieves the top relevant chunks from the vector DB.
The retrieved text becomes context.
The LangChain pipeline passes both soil text and context into Gemini.

ğŸ§© Step 4 â€” Structured Output

**Geminiâ€™s raw output is parsed via a Pydantic model:**
class SoilAnalysis(BaseModel):
    quality: str = Field(..., description="Brief summary of soil quality")
    recommended_crops: list[str] = Field(..., description="List of suitable crops")
    suggestions: str = Field(..., description="Detailed suggestions to improve soil")

**The response is displayed cleanly on Streamlit with sections for:**
ğŸ§ª Soil Quality
ğŸŒ¾ Recommended Crops
ğŸ’¡ Suggestions

**Run the App:**
streamlit run main.py
